{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Leemos el CSV######################\n",
    "df = pd.read_csv('poker-hand-tiny.csv')\n",
    "\n",
    "############Limpiamos el CSV###################\n",
    "for i in range(5,10):\n",
    "    #Creamos lista con los indices a eliminar\n",
    "    idmemor = df[df['Clase']== i].index\n",
    "    #Eliminamos los indices del csv\n",
    "    df = df.drop(idmemor)\n",
    "\n",
    "#Define cada dataset\n",
    "y_train = df.iloc[:,10]\n",
    "x_train = df.iloc[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        S1  C1  S2  C2  S3  C3  S4  C4  S5  C5\n0        1   1   1  13   2   4   2   3   1  12\n1        3  12   3   2   3  11   4   5   2   5\n2        1   9   4   6   1   4   3   2   3   9\n3        1   4   3  13   2  13   2   1   3   6\n4        3  10   2   7   1   2   2  11   4   9\n...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n751440   2   1   4  11   1  10   1  11   3  13\n751441   1   1   1   5   3   2   2   4   1   4\n751442   4   1   3  12   1  10   1  10   3  11\n751443   4   8   4   7   4   7   2   4   1   5\n751444   3   9   1   8   3   7   3   9   3  11\n\n[751445 rows x 10 columns] 0         0\n1         1\n2         1\n3         1\n4         0\n         ..\n751440    4\n751441    4\n751442    4\n751443    4\n751444    4\nName: Clase, Length: 751445, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###################### CREACIÓN DATOS SINTÉTICOS #####################\n",
    "smote = SMOTE()\n",
    "X_train, Y_train = smote.fit_sample(x_train, y_train)\n",
    "print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# ÁRBOL DE DECISIÓN #################\n",
    "arboldecision = DecisionTreeClassifier()\n",
    "parametros = {'criterion': ['gini', 'entropy'],'splitter':['best', 'random'],'max_depth': [1,4,7,8,9,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   param_criterion param_max_depth param_splitter  mean_test_score  \\\n0             gini               1           best         0.225575   \n1             gini               1         random         0.225250   \n2             gini               4           best         0.264441   \n3             gini               4         random         0.270068   \n4             gini               7           best         0.318030   \n5             gini               7         random         0.309243   \n6             gini               8           best         0.347473   \n7             gini               8         random         0.339141   \n8             gini               9           best         0.376835   \n9             gini               9         random         0.374228   \n10            gini              10           best         0.409097   \n11            gini              10         random         0.365663   \n12         entropy               1           best         0.225575   \n13         entropy               1         random         0.220689   \n14         entropy               4           best         0.258455   \n15         entropy               4         random         0.262241   \n16         entropy               7           best         0.305481   \n17         entropy               7         random         0.310861   \n18         entropy               8           best         0.332774   \n19         entropy               8         random         0.318100   \n20         entropy               9           best         0.363681   \n21         entropy               9         random         0.348531   \n22         entropy              10           best         0.391414   \n23         entropy              10         random         0.361488   \n\n    rank_test_score  \n0                21  \n1                23  \n2                18  \n3                17  \n4                13  \n5                15  \n6                 9  \n7                10  \n8                 3  \n9                 4  \n10                1  \n11                5  \n12               21  \n13               24  \n14               20  \n15               19  \n16               16  \n17               14  \n18               11  \n19               12  \n20                6  \n21                8  \n22                2  \n23                7  \n"
     ]
    }
   ],
   "source": [
    "############# VALIDACIÓN CRUZADA - Grid Search ##############\n",
    "clf = GridSearchCV(arboldecision, parametros, cv = 3)\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.cv_results_\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "print(df[['param_criterion', 'param_max_depth', 'param_splitter', 'mean_test_score', 'rank_test_score' ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_score'])\nResulatado Naive Bayes:  [22.83038302 22.64993093 22.5566011 ]\n"
     ]
    }
   ],
   "source": [
    "######## NAIVE BAYES ##########\n",
    "bayes = MultinomialNB()\n",
    "val_cruzada = cross_validate(bayes, X_train, Y_train, cv = 3)\n",
    "print(val_cruzada.keys())\n",
    "print('Resulatado Naive Bayes: ', val_cruzada['test_score']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Resultado Arbol de Decisión: 41.05663089114972\n"
     ]
    }
   ],
   "source": [
    "model = clf.best_estimator_\n",
    "print('Resultado Arbol de Decisión:' , model.score(X_train,Y_train)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 10 and input n_features is 4 ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-98947fbced33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnode_indicator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mleave_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mdecision_path\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mindicates\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mgoes\u001b[0m \u001b[0mthrough\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \"\"\"\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 10 and input n_features is 4 "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "############ Cuento componentes del árbol ###############\n",
    "\n",
    "n_nodes = model.tree_.node_count\n",
    "children_left = model.tree_.children_left\n",
    "children_right = model.tree_.children_right\n",
    "feature = model.tree_.feature\n",
    "threshold = model.tree_.threshold\n",
    "\n",
    "node_indicator = model.decision_path(X_train)\n",
    "\n",
    "leave_id = model.apply(X_train)\n",
    "\n",
    "sample_id = 0\n",
    "node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
    "                                    node_indicator.indptr[sample_id + 1]]\n",
    "\n",
    "print('Rules used to predict sample %s: ' % sample_id)\n",
    "for node_id in node_index:\n",
    "    if leave_id[sample_id] == node_id:\n",
    "        continue\n",
    "\n",
    "    if (X_test[sample_id, feature[node_id]] <= threshold[node_id]):\n",
    "        print(X_test[sample_id, feature[node_id]])\n",
    "        \n",
    "        threshold_sign = \"<=\"\n",
    "    else:\n",
    "        print(X_test[sample_id, feature[node_id]])\n",
    "        print(sample_id)\n",
    "        print(feature[node_id])\n",
    "        print(X_test)\n",
    "        threshold_sign = \">\"\n",
    "\n",
    "    print(\"decision id node %s : (X_test[%s, %s] (= %s) %s %s)\"\n",
    "          % (node_id,\n",
    "             sample_id,\n",
    "             feature[node_id],\n",
    "             X_test[sample_id, feature[node_id]],\n",
    "             threshold_sign,\n",
    "             threshold[node_id]))"
   ]
  }
 ]
}